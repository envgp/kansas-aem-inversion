{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ebf42634-e6c7-424b-899f-8967e386af5e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import libaarhusxyz\n",
    "import pandas as pd\n",
    "import dill\n",
    "def read_em_data_from_dat_xyz(em_data, name_gate_times='gate times', dat_type='dat'):\n",
    "    gate_times = np.array(em_data.info[name_gate_times])\n",
    "    df_em = em_data.flightlines\n",
    "    group_em = df_em.groupby('record')\n",
    "    records = list(group_em.groups.keys())\n",
    "    df_em_collar = group_em[['line_no','utmx','utmy','elevation','altitude_[m]']].mean()\n",
    "\n",
    "    dat_names = ['data_{:d}'.format(ii+1) for ii in range(gate_times.size)]\n",
    "    df_em[dat_names] = em_data.layer_data['data']\n",
    "    if dat_type == 'dat':    \n",
    "        dat_std_names = ['datastd_{:d}'.format(ii+1) for ii in range(gate_times.size)]\n",
    "        df_em[dat_std_names] = em_data.layer_data['datastd']    \n",
    "\n",
    "    em_data_nan = em_data.layer_data['data']\n",
    "    em_data_nan = em_data_nan.replace(9999, np.nan)\n",
    "    n_ch1_active = np.round((~np.isnan(em_data_nan.loc[df_em[df_em.segments==1].index]).values).sum(axis=1).mean())\n",
    "    n_ch2_active = np.round((~np.isnan(em_data_nan.loc[df_em[df_em.segments==2].index]).values).sum(axis=1).mean())\n",
    "    print (f\"Active # of channels: Ch1={n_ch1_active:.0f}, Ch2={n_ch2_active:.0f}\")\n",
    "\n",
    "    inds_lm = (~np.isnan(em_data_nan.loc[df_em[df_em.segments==1].index]).values).sum(axis=0) > 0.\n",
    "    inds_hm = (~np.isnan(em_data_nan.loc[df_em[df_em.segments==2].index]).values).sum(axis=0) > 0.\n",
    "\n",
    "    data_lm = []\n",
    "    data_hm = []\n",
    "    if dat_type == 'dat':\n",
    "        datastd_lm = []\n",
    "        datastd_hm = []\n",
    "    records_inv = []\n",
    "    for i_record in records:\n",
    "        df_tmp = group_em.get_group(i_record)\n",
    "        values = df_tmp[dat_names].values\n",
    "        if dat_type == 'dat':\n",
    "            values_std = df_tmp[dat_std_names].values\n",
    "        if df_tmp.shape[0] == 2:\n",
    "            i_lm = np.argwhere(df_tmp['segments'].values==1)[0][0]                \n",
    "            i_hm = np.argwhere(df_tmp['segments'].values==2)[0][0]\n",
    "            data_lm.append(values[i_lm,inds_lm])\n",
    "            data_hm.append(values[i_hm,inds_hm])\n",
    "            if dat_type == 'dat':\n",
    "                datastd_lm.append(values_std[i_lm,inds_lm])\n",
    "                datastd_hm.append(values_std[i_hm,inds_hm])        \n",
    "            records_inv.append(i_record)\n",
    "    data_lm = np.vstack(data_lm)\n",
    "    data_hm = np.vstack(data_hm)\n",
    "    if dat_type == 'dat':\n",
    "        datastd_lm = np.vstack(datastd_lm)\n",
    "        datastd_hm = np.vstack(datastd_hm)\n",
    "    records_inv = np.hstack(records_inv)\n",
    "    df_em_inv = df_em_collar.loc[records_inv]\n",
    "    times_lm_inv = gate_times[inds_lm]\n",
    "    times_hm_inv = gate_times[inds_hm]    \n",
    "\n",
    "    ch1_names = ['dbdt_ch1gt_{:d}'.format(ii+1) for ii in range(data_lm.shape[1])]\n",
    "    ch2_names = ['dbdt_ch2gt_{:d}'.format(ii+1) for ii in range(data_hm.shape[1])]\n",
    "    if dat_type == 'dat':    \n",
    "        std_ch1_names = ['dbdt_std_ch1gt_{:d}'.format(ii+1) for ii in range(data_lm.shape[1])]\n",
    "        std_ch2_names = ['dbdt_std_ch2gt_{:d}'.format(ii+1) for ii in range(data_hm.shape[1])]    \n",
    "\n",
    "    df_em_inv[ch1_names] = data_lm\n",
    "    df_em_inv[ch2_names] = data_hm\n",
    "    if dat_type == 'dat':    \n",
    "        df_em_inv[std_ch1_names] = datastd_lm\n",
    "        df_em_inv[std_ch2_names] = datastd_hm\n",
    "    \n",
    "    meta_data_dict = {}\n",
    "    meta_data_dict['ch1_names'] = ch1_names\n",
    "    meta_data_dict['ch2_names'] = ch2_names\n",
    "    if dat_type == 'dat':    \n",
    "        meta_data_dict['std_ch1_names'] = std_ch1_names\n",
    "        meta_data_dict['std_ch2_names'] = std_ch2_names\n",
    "    meta_data_dict['ch1_times'] = times_lm_inv\n",
    "    meta_data_dict['ch2_times'] = times_hm_inv\n",
    "    df_em_inv = df_em_inv.replace(9999, np.nan)\n",
    "    return df_em_inv, meta_data_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7175cdc0-e5ab-4463-a434-407b69dc3cdf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "work_dir = \"../data/\"\n",
    "fname = work_dir+\"GMD4_SCI02_MOD_dat.xyz\"\n",
    "aem_data = libaarhusxyz.XYZ(fname)\n",
    "fname = work_dir+\"GMD4_SCI02_MOD_syn.xyz\"\n",
    "aem_data_syn = libaarhusxyz.XYZ(fname)\n",
    "fname = work_dir+\"GMD4_SCI02_MOD_inv.xyz\"\n",
    "aem_model = libaarhusxyz.XYZ(fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c32959c4-6f00-48fc-b342-998ea572e360",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/4m/sc07bkn154s8jfc7xp164by00000gq/T/ipykernel_67076/4289894372.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_em[dat_std_names] = em_data.layer_data['datastd']\n",
      "/var/folders/4m/sc07bkn154s8jfc7xp164by00000gq/T/ipykernel_67076/4289894372.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_em[dat_std_names] = em_data.layer_data['datastd']\n",
      "/var/folders/4m/sc07bkn154s8jfc7xp164by00000gq/T/ipykernel_67076/4289894372.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_em[dat_std_names] = em_data.layer_data['datastd']\n",
      "/var/folders/4m/sc07bkn154s8jfc7xp164by00000gq/T/ipykernel_67076/4289894372.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_em[dat_std_names] = em_data.layer_data['datastd']\n",
      "/var/folders/4m/sc07bkn154s8jfc7xp164by00000gq/T/ipykernel_67076/4289894372.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_em[dat_std_names] = em_data.layer_data['datastd']\n",
      "/var/folders/4m/sc07bkn154s8jfc7xp164by00000gq/T/ipykernel_67076/4289894372.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_em[dat_std_names] = em_data.layer_data['datastd']\n",
      "/var/folders/4m/sc07bkn154s8jfc7xp164by00000gq/T/ipykernel_67076/4289894372.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_em[dat_std_names] = em_data.layer_data['datastd']\n",
      "/var/folders/4m/sc07bkn154s8jfc7xp164by00000gq/T/ipykernel_67076/4289894372.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_em[dat_std_names] = em_data.layer_data['datastd']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Active # of channels: Ch1=20, Ch2=27\n",
      "Active # of channels: Ch1=20, Ch2=27\n"
     ]
    }
   ],
   "source": [
    "df_em_inv, meta_data_dict = read_em_data_from_dat_xyz(aem_data, name_gate_times='gate times (s)')\n",
    "df_em_syn, _ = read_em_data_from_dat_xyz(aem_data_syn, name_gate_times='gate times (s)', dat_type='syn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "22752e6f-3d26-4ac1-83ff-7f30a389ef2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dill.dump(meta_data_dict, open(work_dir+'gmd_4_meta_data.pik', 'wb'))\n",
    "df_em_inv.to_parquet(work_dir+'gmd_4_inv.parquet')\n",
    "df_em_syn.to_parquet(work_dir+'gmd_4_syn.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7a28fc1c-9630-44d9-a648-ad0e1994bc2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pyarrow fastparquet"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
